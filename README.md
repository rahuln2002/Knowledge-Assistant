# **AI-Powered Knowledge Assistant (MVP) ğŸš€**  

This project is an AI-powered **Knowledge Assistant** that extracts keywords, generates summaries, and retrieves relevant information using **Retrieval-Augmented Generation (RAG)**. It integrates **transformers, FAISS, and embedding models** to enhance document understanding and response generation.  

ğŸ”— **Live Deployment:** [Hugging Face Space](https://huggingface.co/spaces/rahuln2002/knowledge-assistant)  

---

## **ğŸ“Œ Features**
âœ… **Summarization** â€“ Extracts key insights from large text inputs  
âœ… **Keyword Extraction** â€“ Identifies important terms from input text  
âœ… **Retrieval-Augmented Generation (RAG)** â€“ Enhances response generation using retrieved knowledge  
âœ… **Embeddings & FAISS** â€“ Uses vector search for fast document retrieval  
âœ… **Flask API Backend** â€“ Handles requests efficiently  
âœ… **Dockerized Deployment** â€“ Fully containerized for seamless execution  

---

## **ğŸ› ï¸ Tech Stack**
- **Backend:** Python, Flask API  
- **Summarization Model:** `facebook/bart-large-cnn`  
- **Embedding Model:** `sentence-transformers/all-MiniLM-L6-v2`  
- **RAG Generation Model:** `meta-llama/Llama-3-8b-chat-hf`  
- **Database:** FAISS-based vector storage  
- **Containerization:** Docker  
- **Deployment:** Hugging Face Spaces  

---

## **ğŸ“Œ API Endpoints**
| **Endpoint**  | **Method** | **Description** |
|--------------|-----------|----------------|
| `/` | GET, POST | Renders the web interface and processes input text for summarization, keyword extraction, or Q&A (RAG) |
| `/summarization` | POST | Summarizes input text based on a specified minimum length |
| `/extract_keywords` | POST | Extracts a specified number of keywords from the input text |
| `/rag` | POST | Processes a user query using the RAG pipeline for retrieval-augmented generation |

---

## **ğŸ“Š RAG Pipeline**
- **Embeddings Model:** `sentence-transformers/all-MiniLM-L6-v2`  
- **FAISS Vector Storage:** Stores document embeddings for efficient retrieval  
- **LLM for Generation:** `meta-llama/Llama-3-8b-chat-hf` generates responses based on retrieved documents  

---

## **ğŸ“ Summarization Module**
- Uses **`facebook/bart-large-cnn`**  
- Automatically **truncates text beyond 1024 tokens**  
- Displays a warning if truncation happens  
- Saves output to a file  

---

## **ğŸ³ Dockerfile Overview**
- Uses **Python 3.12.9-slim-bookworm** as the base image  
- Installs dependencies and required system packages  
- Downloads and stores the **summarization and embedding models** locally  
- Exposes port **7860** and runs the Flask API  

---

## **ğŸ“Œ Installation & Setup**
### **1ï¸âƒ£ Clone the Repository**
```sh
git clone https://github.com/your-repo/knowledge-assistant.git
cd knowledge-assistant
```

### **2ï¸âƒ£ Install Dependencies**
```sh
pip install -r requirements.txt
```

### **3ï¸âƒ£ Run the Application**
```sh
python app.py
```

---

## **ğŸš€ Running with Docker**
### **Build the Docker Image**
```sh
docker build -t knowledge-assistant .
```

### **Run the Container**
```sh
docker run -p 7860:7860 knowledge-assistant
```

---

## **ğŸ› ï¸ Future Enhancements**
- âœ…**Fine-tuning of Custom Models:** Replace current **pretrained models** with **custom fine-tuned** models for better accuracy and domain adaptability.  
- âœ…**More NLP Features:** Extend capabilities beyond summarization, keyword extraction, and RAG to include **named entity recognition (NER), sentiment analysis, text classification, paraphrasing, and text generation**.  
- âœ…**Enhanced RAG Pipeline:** Implement **multi-step retrieval, query expansion, and better chunking strategies** to improve response relevance.  
- âœ…**Multilingual Support:** Extend support for multiple languages in summarization and keyword extraction.  
- âœ…**Improved UI/UX:** Develop a more user-friendly frontend with interactive visualization for extracted keywords and RAG results.  
- âœ…**Scalability Enhancements:** Optimize model loading, caching, and API performance for handling large-scale inputs and concurrent requests.  
- âœ…**Integration with External Data Sources:** Enhance RAG by integrating APIs such as Wikipedia, Arxiv, and other knowledge repositories.  
- âœ…**Model Optimization for Faster Inference:** Explore quantization, distillation, and other model compression techniques to improve latency and efficiency.  
- âœ…**User Authentication & History Tracking:** Enable **user authentication** to allow users to track their history of queries and retrieved information.  

---

## **ğŸ‘¨â€ğŸ’» Contributors**
- **Rahul Nihalani**  

---

## **ğŸ“œ License**
This project is licensed under **MIT License**.